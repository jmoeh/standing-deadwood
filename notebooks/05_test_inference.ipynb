{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/home/jmoehring/.conda/envs/sd-env-12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import random\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import wandb\n",
    "import sys\n",
    "from torch.utils.data import DataLoader, Subset, RandomSampler\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from torchmetrics import Dice\n",
    "from safetensors.torch import load_model\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.dirname(os.path.realpath(os.path.abspath(\"\"))))\n",
    "\n",
    "from unet.train_dataset import DeadwoodDataset\n",
    "from unet.unet_model import UNet\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "run_id = \"a7jnzozl\"\n",
    "experiment = api.run(f\"jmoehring/standing-deadwood-unet-pro/{run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samples = 100\n",
    "epoch = 74\n",
    "fold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amp': True,\n",
       " 'beta': 0.7,\n",
       " 'bins': [0, 0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18, 0.2],\n",
       " 'loss': 'tverskyfocal',\n",
       " 'alpha': 0.3,\n",
       " 'gamma': 2,\n",
       " 'epochs': 100,\n",
       " 'momentum': 0.999,\n",
       " 'no_folds': 3,\n",
       " 'run_fold': 2,\n",
       " 'test_size': 0.2,\n",
       " 'use_wandb': 'true',\n",
       " 'val_every': 5,\n",
       " 'batch_size': 3,\n",
       " 'bce_weight': 0.9,\n",
       " 'images_dir': '/lscratch/standing-deadwood/tiles',\n",
       " 'pos_weight': 12,\n",
       " 'lr_patience': 5,\n",
       " 'num_workers': 8,\n",
       " 'random_seed': 11,\n",
       " 'encoder_name': 'unet',\n",
       " 'weight_decay': 0.0001,\n",
       " 'learning_rate': 1e-05,\n",
       " 'register_file': '/lscratch/standing-deadwood/tiles/register.csv',\n",
       " 'experiment_name': '50k_100e_vanilla_tversky_a03b07g2',\n",
       " 'experiments_dir': '/lscratch/standing-deadwood',\n",
       " 'save_checkpoint': 'true',\n",
       " 'balancing_factor': 0.9,\n",
       " 'epoch_val_samples': 0,\n",
       " 'gradient_clipping': 1,\n",
       " 'epoch_train_samples': 50000,\n",
       " 'gradient_accumulation': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(experiment.config[\"random_seed\"])\n",
    "np.random.seed(experiment.config[\"random_seed\"])\n",
    "torch.manual_seed(experiment.config[\"random_seed\"])\n",
    "torch.cuda.manual_seed_all(experiment.config[\"random_seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_df = pd.read_csv(\"/net/home/jmoehring/scratch/tiles/register.csv\")\n",
    "indexes = register_df[register_df[\"biome\"] == 12].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DeadwoodDataset(\n",
    "    register_df=register_df,\n",
    "    images_dir=\"/net/home/jmoehring/scratch/tiles\",\n",
    "    no_folds=experiment.config[\"no_folds\"],\n",
    "    random_seed=experiment.config[\"random_seed\"],\n",
    "    test_size=experiment.config[\"test_size\"],\n",
    "    register_indexes=None,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_args = {\n",
    "    \"batch_size\": 1,\n",
    "    \"num_workers\": 1,\n",
    "    \"pin_memory\": True,\n",
    "    \"shuffle\": False,\n",
    "}\n",
    "g = torch.Generator()\n",
    "g.manual_seed(experiment.config[\"random_seed\"])\n",
    "val_set = dataset.get_test_set()\n",
    "val_loader = DataLoader(val_set, generator=g, **loader_args)\n",
    "\n",
    "# only sample a subset of the validation set\n",
    "if val_samples > 0:\n",
    "    loader_args[\"shuffle\"] = False\n",
    "    sampler = RandomSampler(val_set, num_samples=val_samples, generator=g)\n",
    "    val_loader = DataLoader(val_set, sampler=sampler, generator=g, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = experiment.name.replace(f\"_fold{fold}\", \"\")\n",
    "model_path = f\"/net/home/jmoehring/experiments/{experiment_name}/fold_{fold}_epoch_{epoch}/model.safetensors\"\n",
    "# preferably use GPU\n",
    "device = torch.device(\"cuda\")\n",
    "# model with three input channels (RGB)\n",
    "if experiment.config[\"encoder_name\"] != \"unet\":\n",
    "    model = smp.Unet(\n",
    "        encoder_name=experiment.config[\"encoder_name\"],\n",
    "        encoder_weights=experiment.config[\"encoder_weights\"],\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "    ).to(memory_format=torch.channels_last)\n",
    "else:\n",
    "    model = UNet(\n",
    "        n_channels=3,\n",
    "        n_classes=1,\n",
    "    ).to(memory_format=torch.channels_last)\n",
    "load_model(model, model_path)\n",
    "model = model.to(memory_format=torch.channels_last, device=device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjmoehring\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/net/home/jmoehring/standing-deadwood/notebooks/wandb/run-20241113_114845-n4uh0e3b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jmoehring/standing-deadwood-unet-pro/runs/n4uh0e3b' target=\"_blank\">50k_100e_vanilla_tversky_a03b07g2_fold2_fold_2_epoch_74_eval</a></strong> to <a href='https://wandb.ai/jmoehring/standing-deadwood-unet-pro' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jmoehring/standing-deadwood-unet-pro' target=\"_blank\">https://wandb.ai/jmoehring/standing-deadwood-unet-pro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jmoehring/standing-deadwood-unet-pro/runs/n4uh0e3b' target=\"_blank\">https://wandb.ai/jmoehring/standing-deadwood-unet-pro/runs/n4uh0e3b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jmoehring/standing-deadwood-unet-pro/runs/n4uh0e3b?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x715480d5c440>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = f\"{experiment.name}_fold_{fold}_epoch_{epoch}_eval\"\n",
    "wandb.init(project=\"standing-deadwood-unet-pro\", name=run_name, resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_table = wandb.Table(columns=[\"step\", \"base_file_name\", \"register_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_image(input):\n",
    "    # Ensure the input tensor is of the correct dtype (if it's not already)\n",
    "    if input.dtype != torch.uint8:\n",
    "        input = input.byte()\n",
    "\n",
    "    # Create an empty tensor to hold the RGB output (3 channels for RGB)\n",
    "    # The shape will be [height, width, 3] where 3 is for RGB channels\n",
    "    rgb_image = torch.zeros((input.shape[0], input.shape[1], 3), dtype=torch.uint8)\n",
    "\n",
    "    # Set the RGB values for pixels with value 1 (Yellow: [255, 255, 0])\n",
    "    rgb_image[input == 1] = torch.tensor([255, 255, 0], dtype=torch.uint8)\n",
    "\n",
    "    # Set the RGB values for pixels with value 255 (Red: [255, 0, 0])\n",
    "    rgb_image[input == 255] = torch.tensor([255, 0, 0], dtype=torch.uint8)\n",
    "\n",
    "    # transform to [3, height, width]\n",
    "    rgb_image = rgb_image.permute(2, 0, 1)\n",
    "\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "\n",
    "for batch, (images, true_masks, _, indexes) in tqdm(\n",
    "    enumerate(val_loader), total=len(val_loader)\n",
    "):\n",
    "    images = images.to(memory_format=torch.channels_last, device=device)\n",
    "    true_masks = true_masks.to(device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_masks = model(images)\n",
    "        pred_masks = torch.sigmoid(pred_masks)\n",
    "        # extend the dataframe by all the results of the batch\n",
    "        for i in range(len(images)):\n",
    "            if step < val_samples:\n",
    "                register_index = indexes[i].item()\n",
    "                image = images[i].float().cpu()\n",
    "                ground_truth = get_log_image(true_masks[i].float().cpu().squeeze())\n",
    "                prediction = get_log_image(\n",
    "                    (pred_masks[i] > 0.5).float().cpu().squeeze()\n",
    "                )\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"image\": wandb.Image(image),\n",
    "                        \"true_mask\": wandb.Image(ground_truth),\n",
    "                        \"pred_mask\": wandb.Image(prediction),\n",
    "                        \"step\": step,\n",
    "                    },\n",
    "                )\n",
    "                text_table.add_data(\n",
    "                    step,\n",
    "                    register_df.iloc[register_index][\"base_file_name\"],\n",
    "                    register_index,\n",
    "                )\n",
    "                step += 1\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"index_table\": text_table})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd-env-12",
   "language": "python",
   "name": "sd-env-12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
