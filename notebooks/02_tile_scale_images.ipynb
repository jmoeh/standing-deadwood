{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import concurrent.futures\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import windows\n",
    "from rasterio.features import geometry_window\n",
    "from tqdm import tqdm\n",
    "import utm\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.dirname(os.path.realpath(os.path.abspath(\"\"))))\n",
    "\n",
    "from unet.parallel import paral\n",
    "\n",
    "\n",
    "os.environ[\"GDAL_PAM_ENABLED\"] = \"NO\"\n",
    "os.environ[\"GDAL_NUM_THREADS\"] = \"50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_width = 1024\n",
    "tile_height = 1024\n",
    "tile_overlap = 512\n",
    "\n",
    "cell_widths = np.arange(0.02, 0.22, 0.02)\n",
    "\n",
    "images_dir = \"/net/data_ssd/tree_mortality_orthophotos/orthophotos/\"\n",
    "masks_dir = \"/net/scratch/jmoehring/masks/\"\n",
    "labels_dir = \"/net/data_ssd/tree_mortality_orthophotos/labels_and_aois/\"\n",
    "metadata_path = \"/net/scratch/jmoehring/metadata_manual_with_resolution.csv\"\n",
    "\n",
    "tiles_out_dir = \"/net/scratch/jmoehring/tiles_1024/\"\n",
    "\n",
    "cores = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_list(arr, target):\n",
    "    index = next((i for i, x in enumerate(arr) if x > target), None)\n",
    "    if index is not None:\n",
    "        shortened_list = arr[index:]\n",
    "        return shortened_list\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows(xmin, ymin, xmax, ymax, tile_width, tile_height, overlap):\n",
    "    xstep = tile_width - overlap\n",
    "    ystep = tile_height - overlap\n",
    "    for x in range(xmin, xmax, xstep):\n",
    "        if x + tile_width > xmax:\n",
    "            x = xmax - tile_width\n",
    "        for y in range(ymin, ymax, ystep):\n",
    "            if y + tile_height > ymax:\n",
    "                y = ymax - tile_height\n",
    "            window = windows.Window(x, y, tile_width, tile_height)\n",
    "            yield window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utm_crs(dr):\n",
    "    utm_northern_range = range(32601, 32661)\n",
    "    utm_southern_range = range(32701, 32761)\n",
    "    epsg_code = dr.crs.to_epsg()\n",
    "    if epsg_code in utm_northern_range or epsg_code in utm_southern_range:\n",
    "        return dr.crs\n",
    "    if epsg_code == 4326:\n",
    "        zone = utm.from_latlon(dr.transform[0], dr.transform[2])\n",
    "        utm_code = 32600 + zone[2]\n",
    "        if zone[3] == \"S\":\n",
    "            utm_code += 100\n",
    "        utm_crs = f\"EPSG:{utm_code}\"\n",
    "        return utm_crs\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown CRS: {epsg_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_dataset_to_utm(dataset, resampling_method):\n",
    "    utm_crs = get_utm_crs(dataset)\n",
    "    default_transform, width, height = rasterio.warp.calculate_default_transform(\n",
    "        dataset.crs, utm_crs, dataset.width, dataset.height, *dataset.bounds\n",
    "    )\n",
    "    kwargs = dataset.meta.copy()\n",
    "    kwargs.update(\n",
    "        {\n",
    "            \"crs\": utm_crs,\n",
    "            \"transform\": default_transform,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "        }\n",
    "    )\n",
    "    memfile = rasterio.io.MemoryFile()\n",
    "    with memfile.open(**kwargs, compress=\"DEFLATE\") as dst:\n",
    "        for i in range(1, dataset.count + 1):\n",
    "            rasterio.warp.reproject(\n",
    "                source=rasterio.band(dataset, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=dataset.transform,\n",
    "                src_crs=dataset.crs,\n",
    "                dst_transform=default_transform,\n",
    "                dst_crs=utm_crs,\n",
    "                resampling=resampling_method,\n",
    "            )\n",
    "    return memfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_dataset_to_cell_width(dataset, cell_width, resampling_method):\n",
    "    kwargs = dataset.meta.copy()\n",
    "    kwargs.update(\n",
    "        {\n",
    "            \"width\": int(\n",
    "                np.ceil(dataset.width * abs(dataset.transform.a) / cell_width)\n",
    "            ),\n",
    "            \"height\": int(\n",
    "                np.ceil(dataset.height * abs(dataset.transform.e) / cell_width)\n",
    "            ),\n",
    "            \"transform\": rasterio.Affine(\n",
    "                cell_width,\n",
    "                0.0,\n",
    "                dataset.transform.c,\n",
    "                0.0,\n",
    "                -cell_width,\n",
    "                dataset.transform.f,\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    memfile = rasterio.io.MemoryFile()\n",
    "    with memfile.open(\n",
    "        **kwargs,\n",
    "        compress=\"DEFLATE\",\n",
    "        tiled=True,\n",
    "        blockxsize=tile_overlap,\n",
    "        blockysize=tile_overlap\n",
    "    ) as dst:\n",
    "        for i in range(1, dataset.count + 1):\n",
    "            rasterio.warp.reproject(\n",
    "                source=rasterio.band(dataset, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=dataset.transform,\n",
    "                src_crs=dataset.crs,\n",
    "                dst_transform=kwargs[\"transform\"],\n",
    "                dst_crs=dataset.crs,\n",
    "                resampling=resampling_method,\n",
    "            )\n",
    "    return memfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(mask_filename):\n",
    "    image_filename = mask_filename.replace(\"_mask.tif\", \".tif\")\n",
    "    mask_filepath = os.path.join(masks_dir, mask_filename)\n",
    "\n",
    "    register_rows = []\n",
    "    if os.path.exists(os.path.join(tiles_out_dir, image_filename.replace(\".tif\", \"\"))):\n",
    "        return\n",
    "    image_filepath = os.path.join(images_dir, image_filename)\n",
    "\n",
    "    file_meta = metadata_df.loc[metadata_df[\"filename\"] == image_filename].to_dict(\n",
    "        \"records\"\n",
    "    )[0]\n",
    "\n",
    "    label_filename = image_filename.replace(\".tif\", \"_polygons.gpkg\")\n",
    "    label_filepath = os.path.join(labels_dir, label_filename)\n",
    "\n",
    "    with rasterio.open(image_filepath) as idr, rasterio.open(mask_filepath) as mdr:\n",
    "        image_memfile = reproject_dataset_to_utm(\n",
    "            idr, rasterio.enums.Resampling.bilinear\n",
    "        )\n",
    "        idr.close()\n",
    "        mask_memfile = reproject_dataset_to_utm(mdr, rasterio.enums.Resampling.nearest)\n",
    "        mdr.close()\n",
    "        image_repojected = rasterio.open(image_memfile, \"r+\")\n",
    "        mask_repojected = rasterio.open(mask_memfile, \"r+\")\n",
    "\n",
    "        gdf_label = gpd.read_file(label_filepath, layer=\"aoi\")\n",
    "        gdf_label = gdf_label.to_crs(image_repojected.crs)\n",
    "\n",
    "        image_out_dir = os.path.join(tiles_out_dir, image_filename.replace(\".tif\", \"\"))\n",
    "        os.makedirs(image_out_dir, exist_ok=True)\n",
    "\n",
    "        for cell_width in sorted(\n",
    "            np.insert(\n",
    "                shorten_list(cell_widths, abs(image_repojected.transform[0])),\n",
    "                0,\n",
    "                abs(image_repojected.transform[0]),\n",
    "            )\n",
    "        ):\n",
    "            cell_width = round(cell_width, 3)\n",
    "\n",
    "            resolution_out_dir = os.path.join(image_out_dir, str(cell_width))\n",
    "            os.makedirs(resolution_out_dir, exist_ok=True)\n",
    "\n",
    "            image_rescaled_memfile = rescale_dataset_to_cell_width(\n",
    "                image_repojected, cell_width, rasterio.enums.Resampling.bilinear\n",
    "            )\n",
    "            mask_rescaled_memfile = rescale_dataset_to_cell_width(\n",
    "                mask_repojected, cell_width, rasterio.enums.Resampling.nearest\n",
    "            )\n",
    "            image_rescaled = rasterio.open(image_rescaled_memfile, \"r+\")\n",
    "            mask_rescaled = rasterio.open(mask_rescaled_memfile, \"r+\")\n",
    "\n",
    "            for _, aoi_row in gdf_label.iterrows():\n",
    "                aoi_window = geometry_window(image_rescaled, [aoi_row.geometry])\n",
    "                xmin, ymin = aoi_window.col_off, aoi_window.row_off\n",
    "                xmax, ymax = xmin + aoi_window.width, ymin + aoi_window.height\n",
    "\n",
    "                for window in get_windows(\n",
    "                    xmin, ymin, xmax, ymax, tile_width, tile_height, tile_overlap\n",
    "                ):\n",
    "                    window_transform = windows.transform(\n",
    "                        window, image_rescaled.transform\n",
    "                    )\n",
    "                    image_tile_metadata = image_rescaled.meta.copy()\n",
    "                    image_tile_metadata.update(\n",
    "                        {\n",
    "                            \"transform\": window_transform,\n",
    "                            \"width\": window.width,\n",
    "                            \"height\": window.height,\n",
    "                        }\n",
    "                    )\n",
    "                    mask_tile_metadata = mask_rescaled.meta.copy()\n",
    "                    mask_tile_metadata.update(\n",
    "                        {\n",
    "                            \"transform\": window_transform,\n",
    "                            \"width\": window.width,\n",
    "                            \"height\": window.height,\n",
    "                        }\n",
    "                    )\n",
    "                    image_tile_name = f\"{window.col_off}_{window.row_off}.tif\"\n",
    "                    mask_tile_name = f\"{window.col_off}_{window.row_off}_mask.tif\"\n",
    "                    image_tile_path = os.path.join(resolution_out_dir, image_tile_name)\n",
    "                    mask_tile_path = os.path.join(resolution_out_dir, mask_tile_name)\n",
    "\n",
    "                    if os.path.exists(image_tile_path) or os.path.exists(\n",
    "                        mask_tile_path\n",
    "                    ):\n",
    "                        continue\n",
    "                    out_image = image_rescaled.read(window=window)\n",
    "                    filled_fraction = 0\n",
    "                    if image_tile_metadata[\"nodata\"] is None:\n",
    "                        filled_fraction = np.count_nonzero(out_image) / out_image.size\n",
    "                    else:\n",
    "                        filled_fraction = (\n",
    "                            np.count_nonzero(out_image != image_tile_metadata[\"nodata\"])\n",
    "                            / out_image.size\n",
    "                        )\n",
    "\n",
    "                    if filled_fraction > 0.99:\n",
    "                        out_mask = mask_rescaled.read(window=window)\n",
    "                        with rasterio.open(\n",
    "                            image_tile_path,\n",
    "                            \"w\",\n",
    "                            **image_tile_metadata,\n",
    "                            compress=\"DEFLATE\",\n",
    "                        ) as dst:\n",
    "                            dst.write(out_image)\n",
    "                            dst.close()\n",
    "                        with rasterio.open(\n",
    "                            mask_tile_path,\n",
    "                            \"w\",\n",
    "                            **mask_tile_metadata,\n",
    "                            compress=\"DEFLATE\",\n",
    "                        ) as dst:\n",
    "                            dst.write(out_mask)\n",
    "                            dst.close()\n",
    "                        register_rows.append(\n",
    "                            {\n",
    "                                \"base_image_name\": image_filename,\n",
    "                                \"image_path\": image_tile_path,\n",
    "                                \"mask_path\": mask_tile_path,\n",
    "                                \"resolution\": cell_width,\n",
    "                                \"x\": window.col_off,\n",
    "                                \"y\": window.row_off,\n",
    "                                \"label_quality\": file_meta[\"label_quality\"],\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            image_rescaled.close()\n",
    "            mask_rescaled.close()\n",
    "            image_rescaled_memfile.close()\n",
    "            mask_rescaled_memfile.close()\n",
    "\n",
    "        image_repojected.close()\n",
    "        mask_repojected.close()\n",
    "        image_memfile.close()\n",
    "        mask_memfile.close()\n",
    "\n",
    "    return register_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(images_dir):\n",
    "#     process_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tqdm(total=len(os.listdir(images_dir))) as pbar:\n",
    "#     with concurrent.futures.ProcessPoolExecutor(max_workers=jobs) as executor:\n",
    "#         futures = [\n",
    "#             executor.submit(process_file, filename)\n",
    "#             for filename in os.listdir(images_dir)\n",
    "#         ]\n",
    "#         # Wait for all futures to complete\n",
    "#         for _ in concurrent.futures.as_completed(futures):\n",
    "#             pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "process_file:   5%|▍         | 12/258 [06:22<1:58:13, 28.84s/jobs]/net/home/jmoehring/.conda/envs/standing-deadwood-env/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "process_file: 100%|██████████| 258/258 [16:13<00:00,  3.77s/jobs] \n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/standing-deadwood/unet/parallel.py:54\u001b[0m, in \u001b[0;36mparal\u001b[0;34m(function, iters, num_cores, progress_bar, backend)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"compute function parallel with arguments in iters.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mfunction(iters[0][0],iters[0][1],...)\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm_joblib(\n\u001b[1;32m     45\u001b[0m     tqdm(\n\u001b[1;32m     46\u001b[0m         desc\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# backend can be loky or threading (or maybe something else)\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/standing-deadwood-env/lib/python3.8/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/standing-deadwood-env/lib/python3.8/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/standing-deadwood-env/lib/python3.8/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/standing-deadwood-env/lib/python3.8/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/standing-deadwood-env/lib/python3.8/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/standing-deadwood-env/lib/python3.8/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "results = paral(process_file, [os.listdir(masks_dir)], num_cores=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_df = pd.DataFrame(register_rows)\n",
    "# register_df.to_csv(\n",
    "#     os.path.join(tiles_out_dir, f\"register_{tile_width}.csv\"), index=False\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
